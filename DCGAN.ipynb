{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Convolutional Generative Adversarial Networks (DCGAN)\n",
    "\n",
    "[original paper](https://arxiv.org/abs/1511.06434) <br>\n",
    "[keras example reference](https://keras.io/examples/generative/dcgan_overriding_train_step/)\n",
    "\n",
    "#### Datasets:\n",
    "[Celeb-a kaggle](https://www.kaggle.com/jessicali9530/celeba-dataset)\n",
    "[Google cartoon](https://google.github.io/cartoonset/download.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# configure the GPU\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_dims = 128\n",
    "latent_size = int(square_dims/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"./dataset/cartoonset100k-small\",\n",
    "    labels=None,\n",
    "    image_size=(square_dims, square_dims),\n",
    "    batch_size=25,\n",
    "    shuffle=True,\n",
    "    color_mode=\"rgb\",\n",
    ").map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 64)        3136      \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 128)       131200    \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 128)       262272    \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 32769     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 429,377\n",
      "Trainable params: 429,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(square_dims, square_dims, 3)),\n",
    "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv2DTranspose -> Reverse Convolution\n",
    "* upscaler\n",
    "* used in encoder and decoder architecture as decompressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 32768)             4227072   \n",
      "                                                                 \n",
      " reshape_6 (Reshape)         (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_18 (Conv2D  (None, 32, 32, 128)      262272    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_24 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_19 (Conv2D  (None, 64, 64, 256)      524544    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_25 (LeakyReLU)  (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_20 (Conv2D  (None, 128, 128, 512)    2097664   \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_26 (LeakyReLU)  (None, 128, 128, 512)     0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 128, 128, 3)       38403     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,149,955\n",
      "Trainable params: 7,149,955\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        layers.Dense(latent_size * latent_size * 128),\n",
    "        layers.Reshape((latent_size, latent_size, 128)),\n",
    "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_gen = keras.optimizers.Adam(1e-4)\n",
    "opt_disc = keras.optimizers.Adam(1e-4)\n",
    "loss_fn = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(f\"./generated/generated_img_{epoch}_{i}.png\")\n",
    "\n",
    "        # save the models\n",
    "        self.model.generator.save(f\"./models/DCGAN/generator/generator_{epoch}\")\n",
    "        self.model.discriminator.save(f\"./models/DCGAN/dis/discriminator_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[25,512,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/generator/conv2d_12/Conv2D_1/Conv2DBackpropInput\n (defined at C:\\Users\\vedan\\AppData\\Local\\Temp/ipykernel_9516/63253887.py:58)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5061]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/generator/conv2d_12/Conv2D_1/Conv2DBackpropInput:\nIn[0] gradient_tape/generator/conv2d_12/Conv2D_1/ShapeN:\t\nIn[1] generator/conv2d_12/Conv2D_1/ReadVariableOp (defined at C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\layers\\convolutional.py:231)\t\nIn[2] gradient_tape/generator/conv2d_12/Sigmoid_1/SigmoidGrad:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 667, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 345, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Temp/ipykernel_9516/2676205370.py\", line 10, in <module>\n>>>     gan.fit(\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Temp/ipykernel_9516/63253887.py\", line 58, in train_step\n>>>     grads = tape.gradient(g_loss, self.generator.trainable_weights)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9516/2676205370.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m gan.fit(\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mGANMonitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[25,512,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/generator/conv2d_12/Conv2D_1/Conv2DBackpropInput\n (defined at C:\\Users\\vedan\\AppData\\Local\\Temp/ipykernel_9516/63253887.py:58)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5061]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/generator/conv2d_12/Conv2D_1/Conv2DBackpropInput:\nIn[0] gradient_tape/generator/conv2d_12/Conv2D_1/ShapeN:\t\nIn[1] generator/conv2d_12/Conv2D_1/ReadVariableOp (defined at C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\layers\\convolutional.py:231)\t\nIn[2] gradient_tape/generator/conv2d_12/Sigmoid_1/SigmoidGrad:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 667, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 345, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Temp/ipykernel_9516/2676205370.py\", line 10, in <module>\n>>>     gan.fit(\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\vedan\\AppData\\Local\\Temp/ipykernel_9516/63253887.py\", line 58, in train_step\n>>>     grads = tape.gradient(g_loss, self.generator.trainable_weights)\n>>> "
     ]
    }
   ],
   "source": [
    "epochs = 100  # In practice, use ~100 epochs\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "generator = keras.models.load_model(\"./models/DCGAN/gen/generator_79\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2055b1f75b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "random_vector = tf.random.normal(shape=(1, latent_dim))\n",
    "output = generator(random_vector)\n",
    "plt.imshow(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94edbaacddaafd6d45ba5506bea1ce8a371c01e0c71d6cc8e1f8803236d6de55"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
