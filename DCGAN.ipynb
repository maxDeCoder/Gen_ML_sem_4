{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Convolutional Generative Adversarial Networks (DCGAN)\n",
    "\n",
    "[original paper](https://arxiv.org/abs/1511.06434) <br>\n",
    "[keras example reference](https://keras.io/examples/generative/dcgan_overriding_train_step/)\n",
    "\n",
    "#### Datasets:\n",
    "[Celeb-a kaggle](https://www.kaggle.com/jessicali9530/celeba-dataset)\n",
    "[Google cartoon](https://google.github.io/cartoonset/download.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# configure the GPU\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_dims = 64\n",
    "latent_size = int(square_dims/8)\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 64)        3136      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 128)       131200    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 128)       262272    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 32769     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 429,377\n",
      "Trainable params: 429,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(square_dims, square_dims, 3)),\n",
    "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv2DTranspose -> Reverse Convolution\n",
    "* upscaler\n",
    "* used in encoder and decoder architecture as decompressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 32768)             4227072   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 32, 32, 128)      262272    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 64, 64, 256)      524544    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 128, 128, 512)    2097664   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 128, 128, 512)     0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 128, 128, 3)       38403     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,149,955\n",
      "Trainable params: 7,149,955\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        layers.Dense(latent_size * latent_size * 128),\n",
    "        layers.Reshape((latent_size, latent_size, 128)),\n",
    "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_gen = keras.optimizers.Adam(1e-4)\n",
    "opt_disc = keras.optimizers.Adam(1e-4)\n",
    "loss_fn = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_offset = 332\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "\n",
    "        epoch+=epoch_offset\n",
    "\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(f\"./generated/generated_img_{epoch}_{i}.png\")\n",
    "\n",
    "        # save the models\n",
    "        self.model.generator.save(f\"./models/DCGAN/generator/generator_{epoch}\")\n",
    "        self.model.discriminator.save(f\"./models/DCGAN/dis/discriminator_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "generator = keras.models.load_model(\"./models/DCGAN/generator/generator_332\")\n",
    "discriminator = keras.models.load_model(\"./models/DCGAN/dis/discriminator_332\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"./dataset/cartoonset100k\",\n",
    "    labels=None,\n",
    "    image_size=(square_dims, square_dims),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    color_mode=\"rgb\",\n",
    ").take(314).map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 24/314 [=>............................] - ETA: 1:01 - d_loss: 0.3183 - g_loss: 4.9524"
     ]
    }
   ],
   "source": [
    "epochs = 400  # In practice, use ~100 epochs\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "generator = keras.models.load_model(\"./models/DCGAN/generator/generator_232\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.take(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_image(image, factor=2):\n",
    "    image = tf.image.resize(image, (image.shape[0] * factor, image.shape[1] * factor))\n",
    "    # image = image / 255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x143670b9f70>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "random_vector = tf.random.normal(shape=(5, latent_dim))\n",
    "output = generator(random_vector)[0]\n",
    "# output = upscale_image(output)\n",
    "plt.imshow(output)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94edbaacddaafd6d45ba5506bea1ce8a371c01e0c71d6cc8e1f8803236d6de55"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
