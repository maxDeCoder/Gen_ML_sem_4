{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# configure the GPU\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg(hr_shape):\n",
    "    vgg = keras.applications.VGG19(include_top=False, weights=\"imagenet\", input_shape=hr_shape)\n",
    "    # vgg.load_weights('./models/VGG19/weights.h5')\n",
    "    vgg.trainable = False\n",
    "    return keras.Model(inputs=vgg.input, outputs=vgg.layers[10].output, name='vgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_shape = (None, None, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B residual block\n",
    "def res_block(_input):\n",
    "    # k3n64s1\n",
    "    res_model = layers.Conv2D(64, (3, 3), padding='same')(_input)\n",
    "    res_model = layers.BatchNormalization(momentum=0.5)(res_model)\n",
    "    res_model = layers.PReLU(shared_axes=[1,2])(res_model)\n",
    "\n",
    "    # k3n64s1\n",
    "    res_model = layers.Conv2D(64, (3, 3), padding='same')(res_model)\n",
    "    res_model = layers.BatchNormalization(momentum=0.5)(res_model)\n",
    "\n",
    "    return layers.add([_input, res_model])\n",
    "\n",
    "def upscale_block(_input):\n",
    "    # k3n256s1\n",
    "    up_model = layers.Conv2D(256, (3, 3), padding='same')(_input)\n",
    "    up_model = layers.UpSampling2D(size=2)(up_model)\n",
    "    up_model = layers.PReLU(shared_axes=[1,2])(up_model)\n",
    "\n",
    "    return up_model\n",
    "\n",
    "def create_generator(_input, num_residual_blocks=16):\n",
    "\n",
    "    # Initial Convolution\n",
    "\n",
    "    # k9n64s1\n",
    "    gen_model = layers.Conv2D(64, (9, 9), padding='same')(_input)\n",
    "    gen_model = layers.PReLU(shared_axes=[1,2])(gen_model)\n",
    "\n",
    "    temp = gen_model\n",
    "\n",
    "    # Residual Blocks\n",
    "    for i in range(num_residual_blocks):\n",
    "        gen_model = res_block(gen_model)\n",
    "\n",
    "    # Post Residual Blocks\n",
    "    \n",
    "    # k3n64s1\n",
    "    gen_model = layers.Conv2D(64, (3, 3), padding='same')(gen_model)\n",
    "    gen_model = layers.BatchNormalization(momentum=0.5)(gen_model)\n",
    "    gen_model = layers.add([gen_model, temp])\n",
    "\n",
    "    # Upsampling\n",
    "\n",
    "    gen_model = upscale_block(gen_model)\n",
    "    gen_model = upscale_block(gen_model)\n",
    "\n",
    "    # Output\n",
    "\n",
    "    # k9n3s1\n",
    "    output = layers.Conv2D(3, (9, 9), padding='same')(gen_model)\n",
    "\n",
    "    return keras.Model(inputs=_input, outputs=output, name='generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_block(_input, filters, strides=1, bn=True):\n",
    "    d_model = layers.Conv2D(filters, (3, 3), strides=strides, padding='same')(_input)\n",
    "    if bn:\n",
    "        d_model = layers.BatchNormalization(momentum=0.8)(d_model)\n",
    "    d_model = layers.LeakyReLU(alpha=0.2)(d_model)\n",
    "    return d_model\n",
    "\n",
    "def discriminator(_input):\n",
    "    # k3n64s1\n",
    "    d_model = discriminator_block(_input, 64, bn=False)\n",
    "    # k3n64s2\n",
    "    d_model = discriminator_block(d_model, 64, strides=2)\n",
    "    # k3n128s1\n",
    "    d_model = discriminator_block(d_model, 128)\n",
    "    # k3n128s2\n",
    "    d_model = discriminator_block(d_model, 128, strides=2)\n",
    "    # k3n256s1\n",
    "    d_model = discriminator_block(d_model, 256)\n",
    "    # k3n256s2\n",
    "    d_model = discriminator_block(d_model, 256, strides=2)\n",
    "    # k3n512s1\n",
    "    d_model = discriminator_block(d_model, 512)\n",
    "    # k3n512s2\n",
    "    d_model = discriminator_block(d_model, 512, strides=2)\n",
    "\n",
    "    d_model = layers.Flatten()(d_model)\n",
    "    d_model = layers.Dense(1024)(d_model)\n",
    "    d_model = layers.LeakyReLU(alpha=0.2)(d_model)\n",
    "    output = layers.Dense(1, activation=\"sigmoid\")(d_model)\n",
    "    \n",
    "    return keras.Model(inputs=_input, outputs=output, name='discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_dim = 64\n",
    "hr_dim = 256\n",
    "load_img_dim = 1024\n",
    "epochs = 100\n",
    "scale_factor = hr_dim // lr_dim\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"./dataset/DIV2K_train_HR\",\n",
    "    labels=None,\n",
    "    image_size=(load_img_dim, load_img_dim),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    color_mode=\"rgb\",\n",
    ").map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enlarge the image to the dim_ratio\n",
    "def unpack(img, dim_ratio):\n",
    "    img = img * 255\n",
    "    img = img.astype(np.uint8)\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.resize((int(img.size[0] * dim_ratio), int(img.size[1])))\n",
    "    return img\n",
    "\n",
    "# enlarges the image in the given axis to the dim_ratio\n",
    "def unpack_in_axis(img, dim_ratio, axis):\n",
    "    img = img * 255\n",
    "    img = img.astype(np.uint8)\n",
    "    img = Image.fromarray(img)\n",
    "\n",
    "    if axis == 1:\n",
    "        img = img.resize((int(img.size[0] * dim_ratio), int(img.size[1])))\n",
    "\n",
    "    if axis == 0:\n",
    "        img = img.resize((int(img.size[0]), int(img.size[1] * dim_ratio)))\n",
    "        \n",
    "    return img\n",
    "\n",
    "\n",
    "# squeezes the image such that both dimensions are divisible by 64\n",
    "def pack(img):\n",
    "    pack_axis = np.argmin(img.shape[:-1])\n",
    "    lower_dim = img.shape[pack_axis]\n",
    "    dim_ratio = img.shape[0] / img.shape[1]\n",
    "    # resize image to the lower dimension\n",
    "    img = img * 255\n",
    "    img = img.astype(np.uint8)\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.resize((int(lower_dim), int(lower_dim)))  \n",
    "    img = np.array(img)\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    return img/255, dim_ratio, pack_axis\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(img):\n",
    "    # create windows\n",
    "    windows = []\n",
    "    img = img[0]\n",
    "    for x in range(0, img.shape[0], hr_dim):\n",
    "        for y in range(0, img.shape[1], hr_dim):\n",
    "            # temp = np.expand_dims(img[x:x+hr_dim, y:y+hr_dim, :], axis=0)\n",
    "            # windows.append(temp)\n",
    "            windows.append(img[x:x+hr_dim, y:y+hr_dim, :])\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = hr_dataset.take(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "windowed_dataset = []\n",
    "for item in tqdm(items):\n",
    "    windowed_dataset.append(create_windows(item))\n",
    "\n",
    "windowed_dataset = np.stack(windowed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolute(img, model):\n",
    "    upscaled = []\n",
    "\n",
    "    for x in range(0, img.shape[0], 64):\n",
    "        for y in range(0, img.shape[1], 64):\n",
    "            temp = np.expand_dims(img[x:x+64, y:y+64, :], axis=0)\n",
    "            # temp = model(np.array(img[x:x+64, y:y+64, :]))\n",
    "            temp = model(temp)\n",
    "            upscaled.append(temp)\n",
    "\n",
    "    return upscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stitch the windows into one image\n",
    "def stitch(windows, dims=None):\n",
    "    # create empty image of the right size\n",
    "    img = np.zeros(dims)\n",
    "    \n",
    "    # loop through windows and add them to the image\n",
    "    x, y = 0, 0\n",
    "    for i in range(len(windows)):\n",
    "        # print(i)\n",
    "        img[x:x+256, y:y+256, :] = windows[i][0]\n",
    "        y += 256\n",
    "        if y >= dims[0]:\n",
    "            y = 0\n",
    "            x += 256  \n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, vgg):\n",
    "        super(SRGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.vgg = vgg\n",
    "\n",
    "    def compile(self, loss_mse, loss_bce, opt_dis, opt_gen):\n",
    "        super(SRGAN, self).compile()\n",
    "        self.loss_mse = loss_mse\n",
    "        self.loss_bce = loss_bce\n",
    "        self.opt_dis = opt_dis\n",
    "        self.opt_gen = opt_gen\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "        self.p_loss_metric = keras.metrics.Mean(name=\"p_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def create_windows(self, img):\n",
    "        # create windows\n",
    "        windows = []\n",
    "        img = img[0]\n",
    "        for x in range(0, img.shape[0], hr_dim):\n",
    "            for y in range(0, img.shape[1], hr_dim):\n",
    "                windows.append(img[x:x+hr_dim, y:y+hr_dim, :])\n",
    "        return np.stack(windows)\n",
    "\n",
    "    # stitch the windows into one image\n",
    "    def stitch(self, windows, dims=None):\n",
    "        # create empty image of the right size\n",
    "        img = np.zeros(dims)\n",
    "        \n",
    "        # loop through windows and add them to the image\n",
    "        x, y = 0, 0\n",
    "        for i in range(len(windows)):\n",
    "            # print(i)\n",
    "            img[x:x+256, y:y+256, :] = windows[i][0]\n",
    "            y += 256\n",
    "            if y >= dims[0]:\n",
    "                y = 0\n",
    "                x += 256  \n",
    "\n",
    "        return img\n",
    "\n",
    "    def downscale(self, x, factor=2):\n",
    "        return tf.image.resize(x, (x.shape[1] // factor, x.shape[2] // factor), method=\"area\")\n",
    "\n",
    "    def train_step(self, hr_img):\n",
    "        image_windows = self.create_windows(hr_img)\n",
    "        lr_img = self.downscale(hr_img, scale_factor)\n",
    "\n",
    "        batch_size = tf.shape(hr_img)[0]\n",
    "        fake_labels = tf.zeros((batch_size, 1))\n",
    "        real_labels = tf.ones((batch_size, 1))\n",
    "        \n",
    "        # add noise to labels \n",
    "        labels = tf.concat([fake_labels, real_labels], axis=0)\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
    "            fake_images = self.generator(lr_img)\n",
    "            \n",
    "            # train discriminator\n",
    "            self.discriminator.trainable = True\n",
    "            d_hr_out = self.discriminator(hr_img)\n",
    "            d_fake_out = self.discriminator(fake_images)\n",
    "\n",
    "            dis_output = tf.concat([d_hr_out, d_fake_out], axis=0)\n",
    "\n",
    "            d_loss = self.loss_bce(dis_output, labels)\n",
    "            # sum all values in d_loss  \n",
    "            d_loss = tf.reduce_sum(d_loss)\n",
    "            \n",
    "            # adversarial loss\n",
    "            adv_loss = self.loss_bce(tf.ones_like(d_fake_out), d_fake_out)\n",
    "\n",
    "            # content loss\n",
    "            gen_features = self.vgg(fake_images)/12.75\n",
    "            hr_features = self.vgg(hr_img)/12.75\n",
    "\n",
    "            content_loss = self.loss_mse(hr_features, gen_features)\n",
    "\n",
    "            # total loss (perceptual loss function = content loss + adversarial loss)\n",
    "            total_loss = content_loss + (1e-3 * adv_loss)\n",
    "\n",
    "        gradients_gen = gen_tape.gradient(total_loss, self.generator.trainable_variables)\n",
    "        gradients_dis = dis_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "        self.opt_gen.apply_gradients(zip(gradients_gen, self.generator.trainable_variables))\n",
    "        self.opt_dis.apply_gradients(zip(gradients_dis, self.discriminator.trainable_variables))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric(d_loss)\n",
    "        self.g_loss_metric(total_loss)\n",
    "        self.p_loss_metric(content_loss)\n",
    "\n",
    "        return {\n",
    "            \"d_loss\": d_loss,\n",
    "            \"g_loss\": total_loss,\n",
    "            \"p_loss\": content_loss\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94edbaacddaafd6d45ba5506bea1ce8a371c01e0c71d6cc8e1f8803236d6de55"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
